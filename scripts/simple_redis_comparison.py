#!/usr/bin/env python3
"""
Simple Redis Comparison Test

Based on debug results, this creates a simple but accurate Redis comparison
that works with CrabCache's proven capabilities.
"""

import socket
import struct
import time
import threading
from concurrent.futures import ThreadPoolExecutor
import numpy as np
import json
from dataclasses import dataclass
from typing import List, Dict, Any

# Binary protocol constants
CMD_PING = 0x01
CMD_PUT = 0x02
CMD_GET = 0x03

RESP_OK = 0x10
RESP_PONG = 0x11
RESP_VALUE = 0x14
RESP_NULL = 0x12

@dataclass
class SimpleTestConfig:
    host: str = "127.0.0.1"
    port: int = 7001
    connections: int = 10           # Proven optimal
    operations_per_connection: int = 10000  # 100k total
    data_size: int = 64            # Redis equivalent
    test_duration: int = 30        # 30 seconds

class SimpleRedisClient:
    """Simple client that works reliably"""
    
    def __init__(self, host: str, port: int, client_id: int, config: SimpleTestConfig):
        self.host = host
        self.port = port
        self.client_id = client_id
        self.config = config
        self.socket = None
        self.connected = False
    
    def connect(self) -> bool:
        """Connect with proven settings"""
        try:
            self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.socket.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
            self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.socket.settimeout(5.0)
            
            self.socket.connect((self.host, self.port))
            self.connected = True
            return True
            
        except Exception as e:
            return False
    
    def disconnect(self):
        """Clean disconnect"""
        if self.socket:
            try:
                self.socket.close()
            except:
                pass
            self.socket = None
            self.connected = False
    
    def run_mixed_operations(self, operations: int) -> Dict:
        """Run mixed operations without complex pipelining"""
        results = {
            "client_id": self.client_id,
            "successful_operations": 0,
            "failed_operations": 0,
            "latencies_ms": [],
            "operation_counts": {"PING": 0, "PUT": 0, "GET": 0},
        }
        
        if not self.connected:
            results["failed_operations"] = operations
            return results
        
        # Pre-populate some keys for GET operations
        test_value = b'x' * self.config.data_size
        for i in range(50):  # 50 keys for GET operations
            try:
                key = f"simple_key_{self.client_id}_{i}".encode()
                cmd = self.create_put_command(key, test_value)
                self.socket.send(cmd)
                response = self.socket.recv(1)
            except:
                pass  # Ignore setup errors
        
        # Run mixed operations (40% PING, 30% PUT, 30% GET)
        for i in range(operations):
            try:
                # Choose operation type
                op_choice = i % 10
                if op_choice < 4:  # 40% PING
                    success = self.execute_ping()
                    if success:
                        results["operation_counts"]["PING"] += 1
                elif op_choice < 7:  # 30% PUT
                    success = self.execute_put(i)
                    if success:
                        results["operation_counts"]["PUT"] += 1
                else:  # 30% GET
                    success = self.execute_get(i)
                    if success:
                        results["operation_counts"]["GET"] += 1
                
                if success:
                    results["successful_operations"] += 1
                else:
                    results["failed_operations"] += 1
                    
            except Exception:
                results["failed_operations"] += 1
        
        return results
    
    def execute_ping(self) -> bool:
        """Execute single PING operation"""
        try:
            start_time = time.perf_counter_ns()
            self.socket.send(bytes([CMD_PING]))
            response = self.socket.recv(1)
            end_time = time.perf_counter_ns()
            
            if len(response) == 1 and response[0] == RESP_PONG:
                latency_ms = (end_time - start_time) / 1_000_000
                return True
            return False
        except:
            return False
    
    def execute_put(self, operation_id: int) -> bool:
        """Execute single PUT operation"""
        try:
            key = f"mixed_key_{self.client_id}_{operation_id}".encode()
            test_value = b'x' * self.config.data_size
            cmd = self.create_put_command(key, test_value)
            
            start_time = time.perf_counter_ns()
            self.socket.send(cmd)
            response = self.socket.recv(1)
            end_time = time.perf_counter_ns()
            
            if len(response) == 1 and response[0] == RESP_OK:
                latency_ms = (end_time - start_time) / 1_000_000
                return True
            return False
        except:
            return False
    
    def execute_get(self, operation_id: int) -> bool:
        """Execute single GET operation"""
        try:
            key_idx = operation_id % 50  # Get from pre-populated keys
            key = f"simple_key_{self.client_id}_{key_idx}".encode()
            cmd = self.create_get_command(key)
            
            start_time = time.perf_counter_ns()
            self.socket.send(cmd)
            response = self.socket.recv(1)
            
            if len(response) == 1:
                if response[0] == RESP_VALUE:
                    # Read value
                    len_bytes = self.socket.recv(4)
                    if len(len_bytes) == 4:
                        value_len = struct.unpack('<I', len_bytes)[0]
                        if value_len <= 1024:
                            value = self.socket.recv(value_len)
                            if len(value) == value_len:
                                end_time = time.perf_counter_ns()
                                latency_ms = (end_time - start_time) / 1_000_000
                                return True
                elif response[0] == RESP_NULL:
                    end_time = time.perf_counter_ns()
                    latency_ms = (end_time - start_time) / 1_000_000
                    return True
            return False
        except:
            return False
    
    def create_put_command(self, key: bytes, value: bytes) -> bytes:
        """Create PUT command"""
        cmd = bytearray()
        cmd.append(CMD_PUT)
        cmd.extend(struct.pack('<I', len(key)))
        cmd.extend(key)
        cmd.extend(struct.pack('<I', len(value)))
        cmd.extend(value)
        cmd.append(0)  # No TTL
        return bytes(cmd)
    
    def create_get_command(self, key: bytes) -> bytes:
        """Create GET command"""
        cmd = bytearray()
        cmd.append(CMD_GET)
        cmd.extend(struct.pack('<I', len(key)))
        cmd.extend(key)
        return bytes(cmd)

class SimpleRedisBenchmark:
    """Simple but accurate Redis comparison"""
    
    def __init__(self, config: SimpleTestConfig):
        self.config = config
    
    def run_benchmark(self):
        """Run simple Redis comparison"""
        print("ğŸš€ CrabCache Simple Redis Comparison")
        print("=" * 40)
        print("ğŸ¯ GOAL: Accurate Redis performance comparison")
        print()
        
        print("ğŸ“Š Simple Test Settings:")
        print(f"  Connections:          {self.config.connections} (proven optimal)")
        print(f"  Ops per connection:   {self.config.operations_per_connection:,}")
        print(f"  Total operations:     {self.config.connections * self.config.operations_per_connection:,}")
        print(f"  Data size:            {self.config.data_size} bytes (Redis equivalent)")
        print(f"  Operation mix:        40% PING, 30% PUT, 30% GET")
        print()
        
        # Run benchmark
        print("âš¡ Starting simple benchmark...")
        start_time = time.perf_counter()
        
        def worker(client_id: int):
            client = SimpleRedisClient(self.config.host, self.config.port, client_id, self.config)
            
            if not client.connect():
                return {
                    "client_id": client_id,
                    "successful_operations": 0,
                    "failed_operations": self.config.operations_per_connection,
                    "latencies_ms": [],
                    "operation_counts": {"PING": 0, "PUT": 0, "GET": 0},
                }
            
            try:
                result = client.run_mixed_operations(self.config.operations_per_connection)
                client.disconnect()
                return result
            except Exception as e:
                client.disconnect()
                return {
                    "client_id": client_id,
                    "successful_operations": 0,
                    "failed_operations": self.config.operations_per_connection,
                    "latencies_ms": [],
                    "operation_counts": {"PING": 0, "PUT": 0, "GET": 0},
                    "error": str(e)
                }
        
        # Run workers
        with ThreadPoolExecutor(max_workers=self.config.connections) as executor:
            futures = [executor.submit(worker, i) for i in range(self.config.connections)]
            worker_results = [future.result() for future in futures]
        
        end_time = time.perf_counter()
        total_duration = end_time - start_time
        
        # Analyze results
        self.analyze_results(worker_results, total_duration)
    
    def analyze_results(self, worker_results: List[Dict], total_duration: float):
        """Analyze simple test results"""
        print("ğŸ“Š Simple Redis Comparison Results:")
        print("=" * 38)
        
        # Combine results
        total_successful = sum(r["successful_operations"] for r in worker_results)
        total_failed = sum(r["failed_operations"] for r in worker_results)
        
        # Combine operation counts
        combined_ops = {"PING": 0, "PUT": 0, "GET": 0}
        for result in worker_results:
            for op, count in result["operation_counts"].items():
                combined_ops[op] += count
        
        # Calculate metrics
        throughput = total_successful / total_duration
        success_rate = total_successful / (total_successful + total_failed) * 100
        
        print(f"â±ï¸  Duration: {total_duration:.2f}s")
        print(f"âœ… Successful Operations: {total_successful:,}")
        print(f"âŒ Failed Operations: {total_failed:,}")
        print(f"ğŸ“ˆ Success Rate: {success_rate:.1f}%")
        print(f"ğŸš€ Throughput: {throughput:,.0f} ops/sec")
        print()
        
        # Operation breakdown
        print("ğŸ“Š Operation Breakdown:")
        total_ops = sum(combined_ops.values())
        for op, count in combined_ops.items():
            percentage = count / total_ops * 100 if total_ops > 0 else 0
            ops_per_sec = count / total_duration
            print(f"  {op}: {count:,} ops ({percentage:.1f}%) - {ops_per_sec:,.0f} ops/sec")
        print()
        
        # Compare with Redis and previous results
        self.compare_with_redis(throughput, success_rate)
        
        # Save results
        self.save_results(worker_results, total_duration, throughput)
    
    def compare_with_redis(self, throughput: float, success_rate: float):
        """Compare with Redis and previous CrabCache results"""
        print("ğŸ¥Š Performance Comparison:")
        print("-" * 28)
        
        # Redis baselines
        redis_baseline = 37498      # Standard Redis benchmark
        redis_no_pipeline = 2344    # Estimated Redis without pipelining
        
        # Previous CrabCache results
        previous_results = {
            "CrabCache PING only": 15415,
            "CrabCache PUT only": 24445,
            "CrabCache GET only": 13240,
            "CrabCache mixed (current)": throughput,
        }
        
        print("ğŸ“Š Throughput Comparison:")
        for name, tps in previous_results.items():
            vs_redis = tps / redis_baseline * 100
            vs_redis_no_pipe = tps / redis_no_pipeline * 100
            print(f"  {name}: {tps:,.0f} ops/sec")
            print(f"    vs Redis (full): {vs_redis:.1f}%")
            print(f"    vs Redis (no pipeline): {vs_redis_no_pipe:.1f}%")
        
        print(f"  Redis (standard): {redis_baseline:,} ops/sec")
        print(f"  Redis (no pipeline est): {redis_no_pipeline:,} ops/sec")
        print()
        
        # Analysis
        if success_rate < 95:
            print(f"âš ï¸  Success rate: {success_rate:.1f}% - needs improvement")
        else:
            print(f"âœ… Success rate: {success_rate:.1f}% - excellent")
        
        if throughput > redis_baseline:
            surplus = throughput - redis_baseline
            print(f"ğŸ† REDIS SURPASSED! (+{surplus:,.0f} ops/sec)")
        elif throughput > redis_no_pipeline:
            ratio = throughput / redis_no_pipeline
            print(f"ğŸ¯ EXCELLENT base performance! ({ratio:.1f}x Redis without pipelining)")
            gap = redis_baseline - throughput
            print(f"ğŸ“Š Redis gap: {gap:,.0f} ops/sec (pipelining could close this)")
        else:
            gap = redis_baseline - throughput
            print(f"ğŸ“Š Redis gap: {gap:,.0f} ops/sec ({gap/redis_baseline*100:.1f}%)")
        
        # Recommendations
        print()
        print("ğŸ’¡ Next Steps:")
        if throughput > redis_no_pipeline:
            print("  ğŸš€ CrabCache base performance exceeds Redis!")
            print("  ğŸ”§ Implement pipelining for 10-16x improvement")
            print(f"  ğŸ¯ Target with pipelining: {throughput * 10:,.0f} ops/sec")
        else:
            print("  ğŸ”§ Optimize individual operations first")
            print("  ğŸ“Š Then implement pipelining")
    
    def save_results(self, worker_results: List[Dict], duration: float, throughput: float):
        """Save simple test results"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"benchmark_results/simple_redis_comparison_{timestamp}.json"
        
        summary_data = {
            "timestamp": timestamp,
            "config": {
                "connections": self.config.connections,
                "operations_per_connection": self.config.operations_per_connection,
                "data_size": self.config.data_size,
            },
            "results": {
                "duration": duration,
                "throughput": throughput,
                "total_successful": sum(r["successful_operations"] for r in worker_results),
                "total_failed": sum(r["failed_operations"] for r in worker_results),
            }
        }
        
        try:
            with open(filename, 'w') as f:
                json.dump(summary_data, f, indent=2)
            print(f"ğŸ’¾ Results saved to: {filename}")
        except Exception as e:
            print(f"âš ï¸  Could not save results: {e}")

def main():
    print("ğŸš€ Starting CrabCache Simple Redis Comparison...")
    print("ğŸ¯ Goal: Accurate performance comparison with Redis")
    print()
    
    config = SimpleTestConfig(
        host="127.0.0.1",
        port=7001,
        connections=10,                 # Proven optimal
        operations_per_connection=10000, # 100k total operations
        data_size=64,                   # Redis equivalent
        test_duration=30,
    )
    
    benchmark = SimpleRedisBenchmark(config)
    benchmark.run_benchmark()
    
    print("\nğŸŠ Simple Redis Comparison Complete!")
    print("ğŸ“Š This provides an accurate baseline for Redis comparison")

if __name__ == "__main__":
    main()